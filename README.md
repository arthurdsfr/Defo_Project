# Project Overview

This research and development project focuses on the automatic and accurate detection of deforestation in critical regions of Brazil: the Brazilian Legal Amazon and the Cerrado. Utilizing advanced Computer Vision and Deep Learning techniques, specifically with the PyTorch framework, we developed semantic segmentation models capable of identifying deforested areas from multispectral satellite images.

The growing impact of deforestation on biodiversity and the global climate demands efficient monitoring solutions. Our goal is to provide a modular and robust tool that assists researchers, environmental agencies, and policymakers in the rapid identification of deforestation events, contributing to the conservation of these vital biomes.
The current project contains the scripts to perform a change detection classification for remote sensing data, specifically for deforestation detection in two Brazilian biomes, the Amazon rainforest(Brazilian Legal Amazon) and Brazilian savannah (Cerrado). Several Neural Networks architectures have been included for use.

âœ¨ Highlights and Key Features

Semantic Segmentation Models: Implementation and experimentation with state-of-the-art architectures (e.g., U-Net, DeepLabV3+, Transformer-based) optimized for deforestation detection and diferent backbones.
Multi-Biome Data: Use of a comprehensive dataset containing satellite imagery (Landsat) and deforestation annotations from three distinct regions of the Brazilian Legal Amazon and representative areas of the Cerrado.
PyTorch Framework: Full development of the training and inference pipeline in PyTorch, ensuring flexibility, performance, and ease of experimentation.
Modular and Replicable Code: Organized code structure that facilitates understanding, modification, and extension of the project to new regions, models, or data types.
Performance Metrics: Rigorous evaluation of models using segmentation metrics (IoU, F1-score, Precision, Recall) to ensure the robustness and reliability of detections.
Results Visualization: Generation of deforestation maps and confidence visualizations to facilitate the interpretation of model results.

ğŸš€ Getting Started

These instructions will guide you through setting up the development environment, obtaining the data, and running the code to train or infer models.

Prerequisites
Make sure you have the following tools installed:

Python 3.8+
Git
Conda or Miniconda (recommended for environment management)
CUDA-compatible GPU (recommended for efficient training and inference)

# Data Download
Such implementation has been evaluated in a change detection task namely deforestation detection where the images used in this project can be found in the following links for the [Amazon Biome](https://drive.google.com/drive/folders/1V4UdYors3m3eXaAHXgzPc99esjQOc3mq?usp=sharing) as well as for the [Cerrado](https://drive.google.com/drive/folders/14Jsw0LRcwifwBSPgFm1bZeDBQvewI8NC?usp=sharing). In the same way, the references can be obtained by clicking in [Amazon references] and [Cerrado references](https://drive.google.com/drive/folders/1n9QZA_0V0Xh8SrW2rsFMvpjonLNQPJ96?usp=sharing).

ğŸ§‘â€ğŸ’» Usage

Model Training and Evaluating

To train a segmentation model for the Legal Amazon and/or Cerrado, use the execute.py script wehre you can configure training parameters, model architecture, and data paths. Then, training, testing and metrics computation scripts will be executed sequentially.

ğŸ“‚ # Project Structure

The following folder organization is designed to promote modularity, scalability, and clarity, essential characteristics in Computer Vision and Deep Learning projects.

```
.
â”œâ”€â”€ data                              # Contains custom PyTorch Dataset definitions and related utilities
â”‚Â Â  â””â”€â”€ DeforestationDataset.py       # Custom PyTorch Dataset for loading deforestation imagery and masks
â”œâ”€â”€ deeplab                           # Implementation of DeepLabV3+ semantic segmentation model
â”‚Â Â  â”œâ”€â”€ aspp.py                       # Atrous Spatial Pyramid Pooling (ASPP) module
â”‚Â Â  â”œâ”€â”€ backbones                     # Various backbone networks for DeepLab (e.g., encoders)
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ drn.py                    # Dilated Residual Network (DRN) backbone
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py               # Python package initialization
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ mobilenet.py              # MobileNet backbone
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ resnet.py                 # ResNet backbone
â”‚Â Â  â”‚Â Â  â””â”€â”€ xception.py               # Xception backbone
â”‚Â Â  â”œâ”€â”€ decoder.py                    # DeepLab's decoder module
â”‚Â Â  â”œâ”€â”€ deeplab.py                    # Main DeepLabV3+ model definition
â”‚Â Â  â””â”€â”€ sync_batchnorm                # Synchronized Batch Normalization implementation
â”‚Â Â      â”œâ”€â”€ batchnorm.py              # Synchronized Batch Normalization layer
â”‚Â Â      â”œâ”€â”€ comm.py                   # Communication utilities for distributed sync_bn
â”‚Â Â      â”œâ”€â”€ __init__.py               # Python package initialization
â”‚Â Â      â”œâ”€â”€ replicate.py              # Module for replicating models across GPUs with sync_bn
â”‚Â Â      â””â”€â”€ unittest.py               # Unit tests for sync_batchnorm (can be ignored during normal use)
â”œâ”€â”€ dino                              # DINO (self-supervised Vision Transformer) related implementations
â”‚Â Â  â”œâ”€â”€ utils.py                      # Utility functions for DINO (e.g., data augmentation, logging)
â”‚Â Â  â””â”€â”€ vision_transformer.py         # Vision Transformer (ViT) model implementation used in DINO
â”œâ”€â”€ get_metrics.py                    # Script to calculate and report various evaluation metrics
â”œâ”€â”€ get_visuals.py                    # Script to generate visual outputs (e.g., predicted masks, comparisons)
â”œâ”€â”€ models                            # Generic model components or wrappers
â”‚Â Â  â”œâ”€â”€ Decoder.py                    # A generic decoder component (potentially shared or for other models)
â”‚Â Â  â”œâ”€â”€ FeatureExtractor.py           # A generic feature extractor component (encoder-like)
â”‚Â Â  â””â”€â”€ models.py                     # Main entry point or wrapper for different model configurations
â”œâ”€â”€ options                           # Centralized configuration management using argparse
â”‚Â Â  â”œâ”€â”€ baseoptions.py                # Base class for common command-line arguments
â”‚Â Â  â”œâ”€â”€ deeplaboptions.py             # Specific options for DeepLab models
â”‚Â Â  â”œâ”€â”€ deforestationoptions.py       # General options related to the deforestation dataset/task
â”‚Â Â  â”œâ”€â”€ dinooptions.py                # Specific options for DINO-related configurations
â”‚Â Â  â”œâ”€â”€ testoptions.py                # Options for the testing script
â”‚Â Â  â”œâ”€â”€ trainoptions.py               # Options for the training script
â”‚Â Â  â””â”€â”€ visualoptions.py              # Options for visualization scripts
â”œâ”€â”€ Prove.py                          # Script for demonstration, proof-of-concept, or specific testing (purpose to be clarified)
â”œâ”€â”€ README.md                         # This project description file
â”œâ”€â”€ test.py                           # Main script for model inference and testing
â”œâ”€â”€ train.py                          # Main script for model training
â”œâ”€â”€ utils                             # Collection of utility functions
â”‚Â Â  â”œâ”€â”€ CustomLosses.py               # Implementations of custom loss functions for segmentation
â”‚Â Â  â””â”€â”€ tools.py                      # General utility functions and helpers
â””â”€â”€ vnet                              # Implementation of V-Net semantic segmentation model
    â”œâ”€â”€ decoder.py                    # V-Net's decoder module
    â””â”€â”€ vnet.py                       # Main V-Net model definition
```
